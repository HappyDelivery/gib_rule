import streamlit as st
import google.generativeai as genai
import pypdf
import os
import time
from datetime import datetime
from google.api_core.exceptions import ResourceExhausted

# --------------------------------------------------------------------------------
# 1. Page Configuration & Style
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬",
    page_icon="ğŸ›ï¸",
    layout="centered"
)

st.markdown("""
    <style>
    .stApp { font-family: 'Pretendard', sans-serif; }
    .stButton>button { border-radius: 8px; font-weight: bold; }
    </style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------------
# 2. State Management & Backend Functions
# --------------------------------------------------------------------------------
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def load_data_and_model():
    # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼)
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        st.session_state.model = next((m for m in model_list if 'flash' in m), model_list[0])
    except Exception as e:
        st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", icon="ğŸš¨")
        st.stop()
    file_path = "regulations.pdf"
    if not os.path.exists(file_path):
        st.error(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHub ì €ì¥ì†Œì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", icon="ğŸ“‚")
        st.stop()
    try:
        with open(file_path, "rb") as f, st.spinner():
            pdf_reader = pypdf.PdfReader(f)
            total_pages = len(pdf_reader.pages)
            text_data = []
            progress_bar = st.progress(0, text="ê·œì •ì§‘ ë¶„ì„ ì‹œì‘...")
            start_time = time.time()
            for i, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                if text:
                    text_data.append(f"--- [Page {i+1}] ---\n{text}")
                elapsed = time.time() - start_time
                avg_time_per_page = elapsed / (i + 1)
                remaining_pages = total_pages - (i + 1)
                eta = max(0, avg_time_per_page * remaining_pages)
                percent_complete = (i + 1) / total_pages
                status_text = f"ê·œì •ì§‘ ë¶„ì„ ì¤‘... {i+1}/{total_pages} í˜ì´ì§€ (ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {int(eta)}ì´ˆ)"
                progress_bar.progress(percent_complete, text=status_text)
            st.session_state.pdf_text = "\n\n".join(text_data)
            progress_bar.empty()
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", icon="ğŸ“„")
        st.stop()
    st.session_state.data_loaded = True


def generate_response(model, query, pdf_text):
    """AI ë‹µë³€ ìƒì„± ë° ì‚¬ìš©ì ì¹œí™”ì  ì˜¤ë¥˜ ì²˜ë¦¬"""
    
    # ====[ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘]====
    system_prompt = f"""
    # **ë‹¹ì‹ ì˜ ì—­í•  ë° ì •ì²´ì„±**
    ë‹¹ì‹ ì€ ì˜¤ì§ ì£¼ì–´ì§„ [ê·œì •ì§‘ ì›ë¬¸]ì˜ ë‚´ìš©ë§Œì„ ë¶„ì„í•˜ê³  ë‹µë³€í•˜ëŠ”, ê³ ë„ë¡œ ì •ë°€í•œ 'ë¬¸ì„œ ë¶„ì„ AI'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ 100% ê·œì •ì§‘ì— ê·¼ê±°í•œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    # **ê·œì¹™ (ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì² ì¹™)**
    1. **ì •ë³´ ì¶œì²˜ ì œí•œ**: ë‹¹ì‹ ì€ ì˜¤ì§ ì•„ë˜ ì œê³µëœ [ê·œì •ì§‘ ì›ë¬¸] ì •ë³´ë§Œì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¹ì‹ ì´ í•™ìŠµí•œ ë‹¤ë¥¸ ì–´ë–¤ ì™¸ë¶€ ì§€ì‹, ì›¹ ì •ë³´, ê°œì¸ì ì¸ ì¶”ë¡ ë„ ì ˆëŒ€ ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•œ ì œ1ì›ì¹™ì…ë‹ˆë‹¤.
    2. **ê·¼ê±° ëª…ì‹œ ì˜ë¬´**: ëª¨ë“  ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ì¸ 'í˜ì´ì§€ ë²ˆí˜¸(Page X)'ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "í•´ë‹¹ ë‚´ìš©ì€ ê·œì •ì§‘ 15í˜ì´ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." ì™€ ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
    3. **ì—†ëŠ” ì •ë³´ ì²˜ë¦¬**: ë§Œì•½ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‚´ìš©ì´ [ê·œì •ì§‘ ì›ë¬¸]ì— ì—†ë‹¤ë©´, ì ˆëŒ€ ë‹µë³€ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹ , ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì´ ì •í•´ì§„ ë¬¸êµ¬ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
       > "ê·œì •ì§‘ ì›ë¬¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì‹œê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ ë³´ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    4. **ë‹µë³€ í˜•ì‹**: ë³µì¡í•œ ì ˆì°¨ë‚˜ ì—¬ëŸ¬ í•­ëª©ì€ ë²ˆí˜¸ ë§¤ê¸°ê¸°ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
    5. **ë§ˆë¬´ë¦¬ ë¬¸êµ¬**: ëª¨ë“  ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
       > "ì„¸ë¶€ ë‚´ìš©ì€ ì •ê´€ê·œì •ì§‘ ì›ë¬¸ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?"

    # **[ê·œì •ì§‘ ì›ë¬¸]**
    {pdf_text}
    """
    # ====[ìˆ˜ì •ëœ ë¶€ë¶„ ë]====

    try:
        ai_model = genai.GenerativeModel(model)
        response = ai_model.generate_content(
            [system_prompt, f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"], 
            generation_config={"temperature": 0.0} # ì°½ì˜ì„±ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ìœ ë„
        )
        return response.text
    except ResourceExhausted:
        return "âš ï¸ **API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼**\n\në¬´ë£Œ API í‚¤ì˜ ë¶„ë‹¹ ìš”ì²­ íšŸìˆ˜(RPM)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. **ì•½ 1ë¶„ í›„ì— ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.**"
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --------------------------------------------------------------------------------
# 3. Main UI Rendering (ì´í•˜ ë‚´ìš©ì€ ëª¨ë‘ ë™ì¼)
# --------------------------------------------------------------------------------
st.title("ğŸ›ï¸ GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬")
st.caption(f"ê¸°ì¤€ì¼: {datetime.now().strftime('%Y-%m-%d')}")
st.divider()

if not st.session_state.data_loaded:
    load_data_and_model()
    st.rerun()

st.markdown("#### ğŸ’¬ ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ì˜ˆì‹œ")
example_questions = {
    "ì¸ì‚¬/ë³µë¬´": ["ì—°ì°¨íœ´ê°€ ì‚¬ìš© ê·œì •", "ë³‘ê°€ ì‹ ì²­ ì ˆì°¨ì™€ í•„ìš” ì„œë¥˜", "ìœ¡ì•„íœ´ì§ ì‹ ì²­ ìê²©"],
    "ë³´ìˆ˜/ê²½ë¹„": ["ì¶œì¥ë¹„ ì •ì‚° ë°©ë²•", "ì‹œê°„ì™¸ê·¼ë¬´ìˆ˜ë‹¹ ì§€ê¸‰ ê¸°ì¤€", "ê²½ì¡°ì‚¬ë¹„ ì§€ê¸‰ ê·œì •"],
    "ê¸°íƒ€": ["ë²•ì¸ì¹´ë“œ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­", "ì •ë³´ë³´ì•ˆ ê´€ë ¨ ê·œì •", "ì°¨ëŸ‰ ìš´í–‰ ë° ê´€ë¦¬ ê·œì •"],
}
selected_category = st.selectbox("ê¶ê¸ˆí•œ ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”.", list(example_questions.keys()))

cols = st.columns(len(example_questions[selected_category]))
for i, question in enumerate(example_questions[selected_category]):
    if cols[i].button(question, use_container_width=True):
        st.session_state.user_query = question
        st.rerun()

st.markdown("---")
st.markdown("#### âœï¸ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
user_query = st.text_area("ê·œì •ì§‘ ë‚´ìš© ì¤‘ ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_query", height=120)

if st.button("AIì—ê²Œ ì§ˆë¬¸í•˜ê¸° ğŸš€", type="primary", use_container_width=True):
    if user_query:
        st.session_state.chat_history.append({"role": "user", "content": user_query})
        with st.spinner("AIê°€ ê·œì •ì§‘ì„ ê²€í† í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response_text = generate_response(st.session_state.model, user_query, st.session_state.pdf_text)
            st.session_state.chat_history.append({"role": "assistant", "content": response_text})
        st.rerun()
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âš ï¸")

st.markdown("---")
st.markdown("#### ğŸ“‹ ë‹µë³€ ê²°ê³¼")
if not st.session_state.chat_history:
    st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•œ í›„ 'AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
else:
    for message in reversed(st.session_state.chat_history):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
