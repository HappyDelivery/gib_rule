import streamlit as st
import google.generativeai as genai
import pypdf
import os
import time
from datetime import datetime
from google.api_core.exceptions import ResourceExhausted

# --------------------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬",
    page_icon="ğŸ›ï¸",
    layout="centered"
)

st.markdown("""
    <style>
    .stApp { font-family: 'Pretendard', sans-serif; }
    .stButton>button { border-radius: 8px; font-weight: bold; }
    .stAlert { border-radius: 10px; }
    </style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------------
# 2. ë°±ì—”ë“œ ë¡œì§ (Full Context & Robust Retry)
# --------------------------------------------------------------------------------

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "full_text" not in st.session_state:
    st.session_state.full_text = ""

def load_data():
    """ì•± ì´ˆê¸°í™”: ê·œì •ì§‘ ì „ì²´ ë¡œë“œ"""
    # 1. API ì„¤ì •
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except Exception as e:
        st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()

    # 2. PDF ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    file_path = "regulations.pdf"
    if not os.path.exists(file_path):
        st.error(f"íŒŒì¼ ì—†ìŒ: {file_path}")
        st.stop()
    
    try:
        with open(file_path, "rb") as f, st.spinner("ê·œì •ì§‘ ì •ë°€ ë¶„ì„ ì¤‘... (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)"):
            pdf_reader = pypdf.PdfReader(f)
            text_data = []
            
            progress = st.progress(0, "í˜ì´ì§€ ë¡œë”© ì¤‘...")
            total = len(pdf_reader.pages)
            
            for i, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                if text:
                    # í˜ì´ì§€ ë²ˆí˜¸ ëª…í™•íˆ ë§ˆí‚¹
                    text_data.append(f"--- [Page {i+1}] ---\n{text}")
                progress.progress((i+1)/total)
            
            progress.empty()
            # ê²€ìƒ‰ ì—†ì´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í†µì§¸ë¡œ ì €ì¥
            st.session_state.full_text = "\n\n".join(text_data)
            
    except Exception as e:
        st.error(f"PDF ì˜¤ë¥˜: {e}")
        st.stop()

    st.session_state.data_loaded = True

def generate_response_full_scan(query):
    """
    [í•µì‹¬ ê¸°ëŠ¥] ì „ì²´ í…ìŠ¤íŠ¸ ìŠ¤ìº” + ê°•ë ¥í•œ ì¬ì‹œë„ ë¡œì§
    - ì¼ë¶€ë§Œ ê²€ìƒ‰í•˜ì§€ ì•Šê³  ì „ì²´ë¥¼ ë³´ë‚´ ì •í™•ë„ 100% í™•ë³´
    - 429 ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì§„ì ìœ¼ë¡œ ëŒ€ê¸°í•˜ë©° ì¬ì‹œë„
    """
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ê·œì •ì§‘ ì „ì²´ë¥¼ ë³´ê³  íŒë‹¨í•˜ë¼ê³  ì§€ì‹œ
    system_prompt = f"""
    ë‹¹ì‹ ì€ 'ë¬¸ì„œ ë¶„ì„ AI'ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ê·œì •ì§‘ ì „ë¬¸]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

    [ê·œì •ì§‘ ì „ë¬¸]
    {st.session_state.full_text}

    [ì‘ì„± ì›ì¹™]
    1. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ê·œì •ì§‘ì˜ ì—¬ëŸ¬ ê³³ì— í©ì–´ì ¸ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ì „ì²´ ë‚´ìš©ì„ ê¼¼ê¼¼íˆ í™•ì¸**í•˜ì—¬ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    2. 'ì œXì¡°' ê°™ì€ ì¡°í•­ì´ ì–¸ê¸‰ë˜ë©´ í•´ë‹¹ ì¡°í•­ì˜ ì‹¤ì œ ë‚´ìš©ë„ ì°¾ì•„ì„œ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”.
    3. ë°˜ë“œì‹œ 'í˜ì´ì§€ ë²ˆí˜¸(Page X)'ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ì„¸ìš”.
    4. ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ê·œì •ì§‘ì—ì„œ ì •í™•í•œ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
    5. ë§ˆì§€ë§‰ ë¬¸êµ¬: "ì„¸ë¶€ ë‚´ìš©ì€ ì •ê´€ê·œì •ì§‘ ì›ë¬¸ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
    """

    # ì¬ì‹œë„ ì„¤ì •
    max_retries = 3
    
    # ì‚¬ìš©í•  ëª¨ë¸: ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ì— ê°•í•˜ê³  ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ ë†’ì€ flash ëª¨ë¸ ê³ ì •
    model_name = "gemini-1.5-flash" 

    for attempt in range(max_retries):
        try:
            ai_model = genai.GenerativeModel(model_name)
            
            # ë‹µë³€ ìƒì„± ìš”ì²­
            response = ai_model.generate_content(
                [system_prompt, f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"],
                generation_config={"temperature": 0.0}
            )
            return response.text
            
        except ResourceExhausted:
            # í•œë„ ì´ˆê³¼ ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            wait_time = (attempt + 1) * 10  # 10ì´ˆ, 20ì´ˆ, 30ì´ˆ ëŒ€ê¸°
            time.sleep(wait_time)
            continue # ë£¨í”„ ë‹¤ì‹œ ì‹¤í–‰
            
        except Exception as e:
            return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
    # 3ë²ˆ ë‹¤ ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    return "âš ï¸ í˜„ì¬ ì‚¬ìš©ìê°€ ë§ì•„ AI ì—°ê²°ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„(ì•½ 1ë¶„ ë’¤) ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."

# --------------------------------------------------------------------------------
# 3. UI ë Œë”ë§
# --------------------------------------------------------------------------------
st.title("ğŸ›ï¸ GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬")
st.caption(f"ê¸°ì¤€ì¼: {datetime.now().strftime('%Y-%m-%d')}")
st.divider()

# ë°ì´í„° ë¡œë“œ
if not st.session_state.data_loaded:
    load_data()
    st.rerun()

# ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ
st.markdown("#### ğŸ’¬ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
example_questions = {
    "ì¸ì‚¬/ë³µë¬´": ["ì—°ì°¨íœ´ê°€ ì‚¬ìš© ê·œì •", "ë³‘ê°€ ì‹ ì²­ ì ˆì°¨", "ìœ¡ì•„íœ´ì§ ìê²©"],
    "ë³´ìˆ˜/ê²½ë¹„": ["ì¶œì¥ë¹„ ì •ì‚° ë°©ë²•", "ì‹œê°„ì™¸ìˆ˜ë‹¹ ì§€ê¸‰ ê¸°ì¤€", "ê²½ì¡°ì‚¬ë¹„ ì§€ê¸‰ ê·œì •"],
    "ê¸°íƒ€": ["ë²•ì¸ì¹´ë“œ ì‚¬ìš© ê·œì •", "ë³´ì•ˆ ë° ì •ë³´ ê´€ë¦¬ ê·œì •", "ì°¨ëŸ‰ ê´€ë¦¬ ê·œì •"]
}
selected_category = st.selectbox("ë¶„ì•¼ ì„ íƒ", list(example_questions.keys()))

cols = st.columns(len(example_questions[selected_category]))
for i, q in enumerate(example_questions[selected_category]):
    if cols[i].button(q, use_container_width=True):
        st.session_state.user_query = q
        st.rerun()

# ì§ì ‘ ì§ˆë¬¸
st.markdown("---")
st.markdown("#### âœï¸ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
user_query = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_query", height=100)

if st.button("ë‹µë³€ ë°›ê¸° ğŸš€", type="primary", use_container_width=True):
    if user_query:
        st.session_state.chat_history.append({"role": "user", "content": user_query})
        
        # ìŠ¤í”¼ë„ˆ ë©”ì‹œì§€ì— ì¬ì‹œë„ ê°€ëŠ¥ì„±ì„ ì–¸ê¸‰
        with st.spinner("ê·œì •ì§‘ ì „ì²´ë¥¼ ê²€í†  ì¤‘ì…ë‹ˆë‹¤... (ë‚´ìš©ì´ ë§ì„ ê²½ìš° ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            response_text = generate_response_full_scan(user_query)
            st.session_state.chat_history.append({"role": "assistant", "content": response_text})
        st.rerun()
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ê²°ê³¼ í‘œì‹œ
st.markdown("---")
if st.session_state.chat_history:
    for message in reversed(st.session_state.chat_history):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
else:
    st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ê·œì •ì§‘ ì „ì²´ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.")
