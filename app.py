import streamlit as st
import google.generativeai as genai
import pypdf
import os
import time
from datetime import datetime

# --------------------------------------------------------------------------------
# 1. Page Configuration & Style
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬",
    page_icon="ğŸ›ï¸",
    layout="centered"
)

st.markdown("""
    <style>
    .stApp { font-family: 'Pretendard', sans-serif; }
    .stButton>button { border-radius: 8px; font-weight: bold; }
    .st-emotion-cache-1ftv3r1 { /* ì§ˆë¬¸/ë‹µë³€ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 10px;
        padding: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------------
# 2. State & Backend Functions
# --------------------------------------------------------------------------------
# --- Session State: ì•±ì˜ ìƒíƒœë¥¼ ê¸°ì–µí•˜ëŠ” ì €ì¥ì†Œ ---
if "initialized" not in st.session_state:
    st.session_state.initialized = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# --- Core Functions ---
def initialize_app():
    """
    ì•± ì´ˆê¸° ì‹¤í–‰ ì‹œ ë‹¨ í•œ ë²ˆë§Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜.
    API ì„¤ì • ë° PDF ë°ì´í„° ë¡œë“œë¥¼ ë‹´ë‹¹.
    """
    # 1. API ì„¤ì •
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        st.session_state.model = next((m for m in model_list if 'flash' in m), model_list[0])
    except Exception as e:
        st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", icon="ğŸš¨")
        st.info("Streamlit Cloudì˜ 'Settings > Secrets'ì— GOOGLE_API_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    # 2. PDF ë¡œë“œ ë° ì²˜ë¦¬ (ì§„í–‰ë¥  í‘œì‹œ ê¸°ëŠ¥ í¬í•¨)
    file_path = "regulations.pdf"
    if not os.path.exists(file_path):
        st.error(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHub ì €ì¥ì†Œ ìµœìƒìœ„ ìœ„ì¹˜ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", icon="ğŸ“‚")
        st.stop()
    
    try:
        with open(file_path, "rb") as f:
            pdf_reader = pypdf.PdfReader(f)
            total_pages = len(pdf_reader.pages)
            text_data = []
            
            # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ UI ìš”ì†Œ ìƒì„±
            progress_bar = st.progress(0, text="ê·œì •ì§‘ ë¶„ì„ ì‹œì‘...")
            start_time = time.time()

            for i, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                if text:
                    text_data.append(f"--- [Page {i+1}] ---\n{text}")

                # ì§„í–‰ë¥  ë° ë‚¨ì€ ì‹œê°„ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                elapsed_time = time.time() - start_time
                avg_time_per_page = elapsed_time / (i + 1)
                remaining_pages = total_pages - (i + 1)
                estimated_time_left = max(0, avg_time_per_page * remaining_pages)
                percent_complete = (i + 1) / total_pages
                status_text = f"ê·œì •ì§‘ ë¶„ì„ ì¤‘... {i+1}/{total_pages} í˜ì´ì§€ (ì•½ {int(estimated_time_left)}ì´ˆ ë‚¨ìŒ)"
                progress_bar.progress(percent_complete, text=status_text)
            
            st.session_state.pdf_text = "\n\n".join(text_data)
            progress_bar.empty() # ì§„í–‰ë°” ì œê±°

    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", icon="ğŸ“„")
        st.stop()

    st.session_state.initialized = True
    st.rerun() # ì´ˆê¸°í™” ì™„ë£Œ í›„ í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë ¤ ë©”ì¸ UIë¥¼ í‘œì‹œ

def generate_response(model, query, pdf_text):
    """AI ë‹µë³€ ìƒì„± í•¨ìˆ˜"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (AIì˜ ì—­í•  ë° ê·œì¹™ ì •ì˜)
    system_prompt = "..." # ì´ì „ ì½”ë“œì™€ ë™ì¼ (ìƒëµ)
    try:
        model = genai.GenerativeModel(model)
        response = model.generate_content([system_prompt, f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"], generation_config={"temperature": 0.1})
        return response.text
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}. (Rate Limitì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.)"

# --------------------------------------------------------------------------------
# 3. Main UI Rendering
# --------------------------------------------------------------------------------
# --- ì´ˆê¸°í™” ë¡œì§ ì‹¤í–‰ ---
if not st.session_state.initialized:
    initialize_app()
else:
    # --- ì´ˆê¸°í™” ì™„ë£Œ í›„ ë©”ì¸ UI ---
    st.title("ğŸ›ï¸ GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬")
    st.caption(f"ê¸°ì¤€ì¼: {datetime.now().strftime('%Y-%m-%d')}")
    st.divider()

    # --- ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ì˜ˆì‹œ ---
    st.markdown("#### ğŸ’¬ ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ì˜ˆì‹œ")
    example_questions = {
        "ì¸ì‚¬/ë³µë¬´": ["ì—°ì°¨íœ´ê°€ ì‚¬ìš© ê·œì •", "ë³‘ê°€ ì‹ ì²­ ì ˆì°¨ì™€ í•„ìš” ì„œë¥˜", "ìœ¡ì•„íœ´ì§ ì‹ ì²­ ìê²©"],
        "ë³´ìˆ˜/ê²½ë¹„": ["ì¶œì¥ë¹„ ì •ì‚° ë°©ë²•", "ì‹œê°„ì™¸ê·¼ë¬´ìˆ˜ë‹¹ ì§€ê¸‰ ê¸°ì¤€", "ê²½ì¡°ì‚¬ë¹„ ì§€ê¸‰ ê·œì •"],
        "ê¸°íƒ€": ["ë²•ì¸ì¹´ë“œ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­", "ì •ë³´ë³´ì•ˆ ê´€ë ¨ ê·œì •", "ì°¨ëŸ‰ ìš´í–‰ ë° ê´€ë¦¬ ê·œì •"],
    }
    selected_category = st.selectbox("ê¶ê¸ˆí•œ ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”.", list(example_questions.keys()))
    
    cols = st.columns(len(example_questions[selected_category]))
    for i, question in enumerate(example_questions[selected_category]):
        if cols[i].button(question, use_container_width=True):
            st.session_state.user_input = question
            st.rerun()

    # --- ì§ì ‘ ì§ˆë¬¸ ì…ë ¥ ---
    st.markdown("---")
    st.markdown("#### âœï¸ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
    user_query = st.text_area("ê·œì •ì§‘ ë‚´ìš© ì¤‘ ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_input", height=120)
    
    col1, col2 = st.columns([3, 2])
    if col1.button("AIì—ê²Œ ì§ˆë¬¸í•˜ê¸° ğŸš€", type="primary", use_container_width=True):
        if user_query:
            st.session_state.chat_history.append({"role": "user", "content": user_query})
            with st.spinner("AIê°€ ê·œì •ì§‘ì„ ê²€í† í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                response_text = generate_response(st.session_state.model, user_query, st.session_state.pdf_text)
                st.session_state.chat_history.append({"role": "assistant", "content": response_text})
            st.session_state.user_input = "" # ì…ë ¥ì°½ ì´ˆê¸°í™”
            st.rerun()
        else:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    col2.link_button("ğŸ‘©â€ğŸ’¼ ì „ë¬¸ê°€ì—ê²Œ ë¬¸ì˜í•˜ê¸°", f"mailto:hr@example.com?subject=ê·œì •ì§‘ ë¬¸ì˜: {user_query}", use_container_width=True)

    # --- ë‹µë³€ ê²°ê³¼ í‘œì‹œ ---
    st.markdown("---")
    st.markdown("#### ğŸ“‹ ë‹µë³€ ê²°ê³¼")
    if not st.session_state.chat_history:
        st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•œ í›„ 'AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
    else:
        # ìµœì‹  ë‹µë³€ì´ ìœ„ë¡œ ì˜¤ë„ë¡ ì—­ìˆœìœ¼ë¡œ í‘œì‹œ
        for message in reversed(st.session_state.chat_history):
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
