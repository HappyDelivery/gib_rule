import streamlit as st
import google.generativeai as genai
import pypdf
import os
import time
from datetime import datetime

# --------------------------------------------------------------------------------
# 1. Page Configuration & Title
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬",
    page_icon="ğŸ›ï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# Custom CSS for a more professional look
st.markdown("""
    <style>
    /* General Styling */
    .stApp {
        font-family: 'Pretendard', sans-serif;
    }
    /* Main container styling */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    /* Expander styling */
    .st-expander {
        border: 1px solid #333;
        border-radius: 10px;
    }
    /* Chat message styling */
    .st-chat-message {
        background-color: #2b2b2b;
        border-radius: 10px;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    </style>
""", unsafe_allow_html=True)


# --------------------------------------------------------------------------------
# 2. Session State Initialization (í•µì‹¬: ìƒíƒœ ìœ ì§€)
# --------------------------------------------------------------------------------
# ì•±ì´ ì¬ì‹¤í–‰ë˜ì–´ë„ ìœ ì§€ë  ë³€ìˆ˜ë“¤ì„ session_stateì— ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "api_key_configured" not in st.session_state:
    st.session_state.api_key_configured = False


# --------------------------------------------------------------------------------
# 3. Helper Functions
# --------------------------------------------------------------------------------
def configure_genai(api_key):
    """API í‚¤ ì„¤ì • ë° ëª¨ë¸ ëª©ë¡ ë¡œë“œ"""
    try:
        genai.configure(api_key=api_key)
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        models.sort(key=lambda x: ('flash' not in x, 'pro' not in x)) # flash, pro ìš°ì„  ì •ë ¬
        st.session_state.api_key_configured = True
        return models
    except Exception as e:
        st.error(f"API í‚¤ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.session_state.api_key_configured = False
        return []

@st.cache_data(show_spinner=False)
def extract_text_from_pdf(file_content):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì§„í–‰ë¥  í‘œì‹œ í¬í•¨)"""
    try:
        pdf_reader = pypdf.PdfReader(file_content)
        total_pages = len(pdf_reader.pages)
        text_data = []
        progress_bar = st.progress(0, text="ê·œì •ì§‘ ë¶„ì„ ì‹œì‘...")
        start_time = time.time()

        for i, page in enumerate(pdf_reader.pages):
            text = page.extract_text()
            if text:
                text_data.append(f"--- [Page {i+1}] ---\n{text}")
            
            elapsed_time = time.time() - start_time
            avg_time_per_page = elapsed_time / (i + 1)
            remaining_pages = total_pages - (i + 1)
            estimated_time_left = max(0, avg_time_per_page * remaining_pages)
            
            percent_complete = (i + 1) / total_pages
            status_text = f"â³ ê·œì •ì§‘ ë¶„ì„ ì¤‘... {i+1}/{total_pages} í˜ì´ì§€ (ì•½ {int(estimated_time_left)}ì´ˆ ë‚¨ìŒ)"
            progress_bar.progress(percent_complete, text=status_text)
        
        progress_bar.empty()
        return "\n\n".join(text_data)
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

def generate_response(model, query, pdf_text, temperature):
    """Gemini ëª¨ë¸ì„ í†µí•´ ë‹µë³€ ìƒì„±"""
    system_prompt = f"""
    ë‹¹ì‹ ì€ 'GIB' ê¸°ê´€ì˜ ì •ê´€ ë° ê·œì • ì „ë¬¸ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ [ê·œì •ì§‘ ë‚´ìš©]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

    [ê·œì •ì§‘ ë‚´ìš©]
    {pdf_text}

    [ë‹µë³€ ì‘ì„± 5ëŒ€ ì›ì¹™]
    1. **ê·¼ê±° ì œì‹œ**: ë‹µë³€ì˜ í•µì‹¬ ë‚´ìš©ë§ˆë‹¤ ë°˜ë“œì‹œ ê´€ë ¨ ê·¼ê±°ê°€ ë˜ëŠ” ì¡°í•­ê³¼ 'í˜ì´ì§€ ë²ˆí˜¸(Page X)'ë¥¼ ëª…í™•íˆ ì¸ìš©í•˜ì„¸ìš”.
    2. **ì •í™•ì„±**: [ê·œì •ì§‘ ë‚´ìš©]ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”. ì •ë³´ê°€ ì—†ë‹¤ë©´ "ê·œì •ì§‘ ì›ë¬¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
    3. **ê°€ë…ì„±**: ë³µì¡í•œ ì ˆì°¨ë‚˜ ì—¬ëŸ¬ í•­ëª©ì€ ë²ˆí˜¸ ë§¤ê¸°ê¸°(1., 2., 3.)ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(â€¢)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…ë£Œí•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
    4. **ì¹œì ˆí•œ ì•ˆë‚´ì í†¤**: í•­ìƒ ì „ë¬¸ê°€ì ì´ë©´ì„œë„ ì¹œì ˆí•œ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    5. **ë§ˆë¬´ë¦¬ ë¬¸êµ¬**: ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš”: "ì„¸ë¶€ ë‚´ìš©ì€ ì •ê´€ê·œì •ì§‘ ì›ë¬¸ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
    """
    try:
        model = genai.GenerativeModel(model)
        response = model.generate_content(
            [system_prompt, f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"],
            generation_config={"temperature": temperature}
        )
        return response.text
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# --------------------------------------------------------------------------------
# 4. Main UI Rendering
# --------------------------------------------------------------------------------
st.title("ğŸ›ï¸ GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬")
st.caption(f"ìµœì¢… ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d')}")

# --- ì„¤ì • Expander ---
with st.expander("âš™ï¸ ì´ˆê¸° ì„¤ì • (API Key & ê·œì •ì§‘)", expanded=not st.session_state.api_key_configured or not st.session_state.pdf_text):
    # API Key ì…ë ¥
    api_key_input = st.text_input("Google Gemini API Key", type="password", value=st.secrets.get("GOOGLE_API_KEY", ""))
    
    if api_key_input:
        available_models = configure_genai(api_key_input)
    else:
        st.warning("Google Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        available_models = []

    if st.session_state.api_key_configured:
        st.success("API Keyê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì„ íƒ
        selected_model = st.selectbox("ğŸ¤– ë‹µë³€ ìƒì„± ëª¨ë¸ ì„ íƒ", available_models)
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader("ê·œì •ì§‘ PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")
        if uploaded_file:
            st.session_state.pdf_text = extract_text_from_pdf(uploaded_file)
            if st.session_state.pdf_text:
                st.success(f"âœ… '{uploaded_file.name}' ë¶„ì„ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# --- ë©”ì¸ ë¡œì§: ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œë§Œ í‘œì‹œ ---
if st.session_state.api_key_configured and st.session_state.pdf_text:
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‹œ ì§ˆë¬¸ (UX ê°œì„ )
    st.markdown("---")
    st.subheader("ğŸ’¡ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬")
    cols = st.columns(3)
    example_questions = {
        "íœ´ê°€/íœ´ì§": "ì—°ì°¨ ì‚¬ìš© ê·œì •ê³¼ ë³‘ê°€ ì‹ ì²­ ì ˆì°¨ë¥¼ ì•Œë ¤ì¤˜.",
        "ì¶œì¥/ê²½ë¹„": "êµ­ë‚´ ì¶œì¥ ì‹œ êµí†µë¹„ì™€ ìˆ™ë°•ë¹„ ì •ì‚° ê¸°ì¤€ì´ ì–´ë–»ê²Œ ë¼?",
        "ì¸ì‚¬/í‰ê°€": "ìŠ¹ì§„ ì‹¬ì‚¬ ê¸°ì¤€ê³¼ í‰ê°€ ì ˆì°¨ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜."
    }
    
    # ê° ë²„íŠ¼ì— ê³ ìœ í•œ keyë¥¼ ë¶€ì—¬
    if cols[0].button("ğŸŒ´ íœ´ê°€/íœ´ì§", use_container_width=True, key="cat_vacation"):
        st.session_state.preset_query = example_questions["íœ´ê°€/íœ´ì§"]
    if cols[1].button("âœˆï¸ ì¶œì¥/ê²½ë¹„", use_container_width=True, key="cat_biztrip"):
        st.session_state.preset_query = example_questions["ì¶œì¥/ê²½ë¹„"]
    if cols[2].button("ğŸ“ˆ ì¸ì‚¬/í‰ê°€", use_container_width=True, key="cat_hr"):
        st.session_state.preset_query = example_questions["ì¸ì‚¬/í‰ê°€"]
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê·œì •ì§‘ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.", key="chat_input"):
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì˜ˆì‹œ ì§ˆë¬¸ì´ ìˆë‹¤ë©´, ê·¸ê²ƒì„ ì‚¬ìš©
        if "preset_query" in st.session_state and st.session_state.preset_query:
            prompt = st.session_state.preset_query
            del st.session_state.preset_query # ì‚¬ìš© í›„ ì‚­ì œ

        # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ë‹µë³€ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = generate_response(
                    model=selected_model,
                    query=prompt,
                    pdf_text=st.session_state.pdf_text,
                    temperature=0.1  # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ë¡œ ì„¤ì •
                )
                st.markdown(response)
        
        # AI ë‹µë³€ì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
        st.session_state.chat_history.append({"role": "assistant", "content": response})

else:
    st.info("ğŸ‘† ìƒë‹¨ì˜ 'ì´ˆê¸° ì„¤ì •'ì„ ì—´ì–´ API Keyë¥¼ ì…ë ¥í•˜ê³  ê·œì •ì§‘ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
