import streamlit as st
import google.generativeai as genai
import pypdf
import os
import time
from datetime import datetime
from google.api_core.exceptions import ResourceExhausted

# --------------------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬",
    page_icon="ğŸ›ï¸",
    layout="centered"
)

st.markdown("""
    <style>
    .stApp { font-family: 'Pretendard', sans-serif; }
    .stButton>button { border-radius: 8px; font-weight: bold; }
    /* ë‹µë³€ ì˜ì—­ ìŠ¤íƒ€ì¼ */
    .st-emotion-cache-1v0mbdj { border-radius: 10px; }
    </style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------------
# 2. ë°±ì—”ë“œ ë¡œì§ (ëª¨ë¸ ë‹¤ì¤‘í™” & ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰)
# --------------------------------------------------------------------------------

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "pdf_pages" not in st.session_state:
    st.session_state.pdf_pages = [] # í˜ì´ì§€ë³„ ë¶„í•  ì €ì¥

def get_relevant_context(query, pages, top_k=5):
    """
    [í•µì‹¬ ê¸°ëŠ¥] PDF ì „ì²´ë¥¼ ë‹¤ ë³´ë‚´ì§€ ì•Šê³ , ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í˜ì´ì§€ë§Œ ì°¾ì•„ì„œ ë³´ëƒ„ (í† í° ì ˆì•½)
    - ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ ì‚¬ìš© (ì†ë„ ë¹ ë¦„, í† í° ì ˆì•½ ìµœì í™”)
    """
    query_keywords = query.split()
    scored_pages = []
    
    for i, page_text in enumerate(pages):
        score = 0
        for keyword in query_keywords:
            if keyword in page_text:
                score += 1
        if score > 0:
            scored_pages.append((score, page_text))
    
    # ê´€ë ¨ë„ ìˆœ ì •ë ¬ í›„ ìƒìœ„ kê°œ í˜ì´ì§€ ì¶”ì¶œ
    scored_pages.sort(key=lambda x: x[0], reverse=True)
    selected_pages = [p[1] for p in scored_pages[:top_k]]
    
    # ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´(í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜), ì•ë¶€ë¶„ 3í˜ì´ì§€ë§Œ ë³´ëƒ„ (ì„œë¡ /ëª©ì°¨ ë“±)
    if not selected_pages:
        return "\n\n".join(pages[:3])
    
    return "\n\n".join(selected_pages)

def load_data_and_models():
    """ì•± ì´ˆê¸°í™”: API ì„¤ì • ë° PDF ë¡œë“œ"""
    # 1. API ì„¤ì • ë° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ë³´
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ëª¨ë‘ ê°€ì ¸ì™€ì„œ Flash -> Pro ìˆœì„œë¡œ ì •ë ¬ (Flashê°€ ì‹¸ê³  ë¹ ë¦„)
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        # ìš°ì„ ìˆœìœ„: Flash > Pro > ë‚˜ë¨¸ì§€
        sorted_models = sorted(all_models, key=lambda x: (0 if 'flash' in x else 1 if 'pro' in x else 2))
        st.session_state.available_models = sorted_models
        
    except Exception as e:
        st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()

    # 2. PDF ë¡œë“œ (í˜ì´ì§€ë³„ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥)
    file_path = "regulations.pdf"
    if not os.path.exists(file_path):
        st.error(f"íŒŒì¼ ì—†ìŒ: {file_path}")
        st.stop()
    
    try:
        with open(file_path, "rb") as f, st.spinner("ê·œì •ì§‘ ë¶„ì„ ì¤‘..."):
            pdf_reader = pypdf.PdfReader(f)
            st.session_state.pdf_pages = []
            
            # ì§„í–‰ë°”
            progress = st.progress(0, "í˜ì´ì§€ ë¶„ì„ ì¤‘...")
            total = len(pdf_reader.pages)
            
            for i, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                if text:
                    # í˜ì´ì§€ ë²ˆí˜¸ ë§ˆí‚¹í•˜ì—¬ ì €ì¥
                    st.session_state.pdf_pages.append(f"--- [Page {i+1}] ---\n{text}")
                progress.progress((i+1)/total)
            
            progress.empty()
            
    except Exception as e:
        st.error(f"PDF ì˜¤ë¥˜: {e}")
        st.stop()

    st.session_state.data_loaded = True

def generate_response_with_fallback(query):
    """
    [í•µì‹¬ ê¸°ëŠ¥] ëª¨ë¸ ìë™ ìš°íšŒ (Fallback) ì‹œìŠ¤í…œ
    - 1ìˆœìœ„ ëª¨ë¸ì´ ì‹¤íŒ¨í•˜ë©´ ìë™ìœ¼ë¡œ 2ìˆœìœ„, 3ìˆœìœ„ ëª¨ë¸ë¡œ êµì²´í•˜ì—¬ ì¬ì‹œë„
    """
    
    # 1. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í˜ì´ì§€ ì¶”ì¶œ (í† í° ì ˆì•½)
    relevant_context = get_relevant_context(query, st.session_state.pdf_pages)
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ 'ë¬¸ì„œ ë¶„ì„ AI'ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ê´€ë ¨ ê·œì • ë‚´ìš©]ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

    [ê´€ë ¨ ê·œì • ë‚´ìš© (ë°œì·Œ)]
    {relevant_context}

    [ì‘ì„± ì›ì¹™]
    1. ë°˜ë“œì‹œ ì œê³µëœ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µí•˜ì„¸ìš”. ì™¸ë¶€ ì •ë³´ ì‚¬ìš© ê¸ˆì§€.
    2. ë‹µë³€ì—ëŠ” 'í˜ì´ì§€ ë²ˆí˜¸'ë¥¼ ê¼­ ëª…ì‹œí•˜ì„¸ìš”. (ì˜ˆ: Page 12)
    3. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì œê³µëœ ê·œì • ë‚´ìš©ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
    4. ë§ˆì§€ë§‰ ë¬¸êµ¬: "ì„¸ë¶€ ë‚´ìš©ì€ ì •ê´€ê·œì •ì§‘ ì›ë¬¸ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë” ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
    """

    # 2. ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ì‹œë„ (Fallback)
    models = st.session_state.get("available_models", [])
    if not models:
        return "ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    last_error = ""
    
    for model_name in models:
        try:
            # ëª¨ë¸ ë³€ê²½ ì‹œë„ ì•Œë¦¼ (ë¡œê·¸ ì„±ê²©, í™”ë©´ì—” í‘œì‹œ X)
            # print(f"Trying model: {model_name}") 
            
            ai_model = genai.GenerativeModel(model_name)
            response = ai_model.generate_content(
                [system_prompt, f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"],
                generation_config={"temperature": 0.0}
            )
            return response.text # ì„±ê³µ ì‹œ ë°”ë¡œ ë°˜í™˜
            
        except ResourceExhausted:
            # í•œë„ ì´ˆê³¼ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°
            continue 
        except Exception as e:
            last_error = str(e)
            continue
            
    # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    return f"âš ï¸ ì£„ì†¡í•©ë‹ˆë‹¤. ëª¨ë“  AI ëª¨ë¸ì´ í˜„ì¬ ì‚¬ìš©ëŸ‰ì´ ë§ì•„ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n(ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error})\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# --------------------------------------------------------------------------------
# 3. UI ë Œë”ë§
# --------------------------------------------------------------------------------
st.title("ğŸ›ï¸ GIB ì •ê´€ê·œì •ì§‘ AI ìƒë‹´ì‚¬")
st.caption(f"ê¸°ì¤€ì¼: {datetime.now().strftime('%Y-%m-%d')}")
st.divider()

# ë°ì´í„° ë¡œë“œ
if not st.session_state.data_loaded:
    load_data_and_models()
    st.rerun()

# ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ
st.markdown("#### ğŸ’¬ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
example_questions = {
    "ì¸ì‚¬/ë³µë¬´": ["ì—°ì°¨íœ´ê°€ ì‚¬ìš© ê·œì •", "ë³‘ê°€ ì‹ ì²­ ì ˆì°¨", "ìœ¡ì•„íœ´ì§ ìê²©"],
    "ë³´ìˆ˜/ê²½ë¹„": ["ì¶œì¥ë¹„ ì •ì‚° ë°©ë²•", "ì‹œê°„ì™¸ìˆ˜ë‹¹ ê¸°ì¤€", "ê²½ì¡°ì‚¬ë¹„ ì§€ê¸‰"],
    "ê¸°íƒ€": ["ë²•ì¸ì¹´ë“œ ì‚¬ìš© ê·œì •", "ë³´ì•ˆ ê·œì •", "ì°¨ëŸ‰ ê´€ë¦¬"]
}
selected_category = st.selectbox("ë¶„ì•¼ ì„ íƒ", list(example_questions.keys()))

cols = st.columns(len(example_questions[selected_category]))
for i, q in enumerate(example_questions[selected_category]):
    if cols[i].button(q, use_container_width=True):
        st.session_state.user_query = q
        st.rerun()

# ì§ì ‘ ì§ˆë¬¸
st.markdown("---")
st.markdown("#### âœï¸ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
user_query = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_query", height=100)

if st.button("ë‹µë³€ ë°›ê¸° ğŸš€", type="primary", use_container_width=True):
    if user_query:
        st.session_state.chat_history.append({"role": "user", "content": user_query})
        
        with st.spinner("AI ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # ê°œì„ ëœ Fallback í•¨ìˆ˜ í˜¸ì¶œ
            response_text = generate_response_with_fallback(user_query)
            st.session_state.chat_history.append({"role": "assistant", "content": response_text})
        st.rerun()
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ê²°ê³¼ í‘œì‹œ
st.markdown("---")
if st.session_state.chat_history:
    for message in reversed(st.session_state.chat_history):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
else:
    st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ê·œì •ì§‘ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.")
